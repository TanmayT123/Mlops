import shap
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import shap.plots as sp

# Step 1: Load dataset
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target

# Step 2: Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Train Random Forest model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 4: Create SHAP explainer
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# Step 5: Generate SHAP summary plots for each class (multi-class safe)
if isinstance(shap_values, list):  # multi-class model
    for class_idx, class_name in enumerate(iris.target_names):
        print(f"\nðŸ“Š Generating SHAP summary for class: {class_name}")
        values = np.array(shap_values[class_idx])
        shap.summary_plot(values, X_test, plot_type="bar", show=False)
        plt.title(f"Feature Importance for Class: {class_name}")
        plt.savefig(f"shap_summary_{class_name}.png", bbox_inches="tight")
        plt.close()
else:  # single-class model
    print("\nðŸ“Š Generating single-class SHAP summary")
    shap.summary_plot(shap_values, X_test, plot_type="bar", show=False)
    plt.title("Feature Importance (Single Model)")
    plt.savefig("shap_summary.png", bbox_inches="tight")
    plt.close()

# Step 6: Local explanation for one sample
sample_idx = 0
print("\nðŸŽ¯ Generating local explanation for one prediction...")

if isinstance(shap_values, list):
    # Multi-class â†’ explain class 0 (Setosa)
    base_value = explainer.expected_value[0]
    sample_values = shap_values[0][sample_idx, :]
else:
    base_value = explainer.expected_value
    sample_values = shap_values[sample_idx, :]

# Force plot (v0.45 syntax)
sp.force(base_value, sample_values)

plt.title("Local Explanation for One Prediction")
plt.savefig("shap_local_explanation.png", bbox_inches="tight")
plt.close()

print("\nâœ… SHAP explainability completed successfully!")
print("Saved plots in your folder: shap_summary_*.png and shap_local_explanation.png")



python.py
